# Condition Invariance for Autonomous Driving by Adversarial Learning

Object detection is a crucial task in autonomous driving, where domain shifting between the training and the test set is one of the main reasons behind the poor performance of a detector when deployed. Some erroneous priors may be learned in this situation, therefore a model must be invariant to conditions that might promote them. To tackle this problem, we propose an adversarial learning framework consisting of an encoder, an object-detector and condition-classifier. The encoder is trained to deceive the condition-classifier and aid the object-detector as much as possible throughout the learning stage, in order to obtain highly discriminative features. Experiments showed that this framework is not very competitive regarding the trade-off between precision and recall, but it does improve the ability of the model to detect smaller objects and some object classes.
